{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question2_apriori.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K1zueKeRAnr",
        "outputId": "2bcfc186-01e0-49b0-c85b-96be71ef4b18"
      },
      "source": [
        "!gdown --id 1o7B8XJ33OjCo8paZytvvVsxncm9wvVke\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1o7B8XJ33OjCo8paZytvvVsxncm9wvVke\n",
            "To: /content/BigData_Homework1_Data.zip\n",
            "377MB [00:03, 117MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOvDgyGUurEj",
        "outputId": "b4779896-3c79-493a-f283-02d23729aa58"
      },
      "source": [
        "!unzip BigData_Homework1_Data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  BigData_Homework1_Data.zip\n",
            "   creating: Data/\n",
            "   creating: Data/question 2_Association rules' application/\n",
            "  inflating: Data/question 2_Association rules' application/browsing.txt  \n",
            "   creating: Data/question 3_LSH/\n",
            "   creating: Data/question 3_LSH/data/\n",
            "  inflating: Data/question 3_LSH/data/patches.csv  \n",
            "  inflating: Data/question 3_LSH/lsh.py  \n",
            "   creating: Data/question 4_Data streams/\n",
            "  inflating: Data/question 4_Data streams/counts.txt  \n",
            "  inflating: Data/question 4_Data streams/counts_tiny.txt  \n",
            "  inflating: Data/question 4_Data streams/hash_params.txt  \n",
            "  inflating: Data/question 4_Data streams/words_stream.txt  \n",
            "  inflating: Data/question 4_Data streams/words_stream_tiny.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEF9nmh0u-K1"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import combinations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA3O2WeLvI9c"
      },
      "source": [
        "def create_candidate_1(X):\n",
        "    \"\"\"\n",
        "    create the 1-item candidate,\n",
        "    it's basically creating a frozenset for each unique item\n",
        "    and storing them in a list\n",
        "    \"\"\"\n",
        "    c1 = []\n",
        "    for transaction in X:\n",
        "        for t in transaction:\n",
        "            t = frozenset([t])\n",
        "            if t not in c1:\n",
        "                c1.append(t)\n",
        "    return c1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rvW5tRWvLG_"
      },
      "source": [
        "def create_candidate_k(freq_item, k):\n",
        "    \"\"\"create the list of k-item candidate\"\"\"\n",
        "    ck = []\n",
        "\n",
        "    # for generating candidate of size two (2-itemset)\n",
        "    if k == 0:\n",
        "        for f1, f2 in combinations(freq_item, 2):\n",
        "            item = f1 | f2  # union of two sets\n",
        "            ck.append(item)\n",
        "    else:\n",
        "        for f1, f2 in combinations(freq_item, 2):\n",
        "            # if the two (k+1)-item sets has\n",
        "            # k common elements then they will be\n",
        "            # unioned to be the (k+2)-item candidate\n",
        "            intersection = f1 & f2\n",
        "            if len(intersection) == k:\n",
        "                item = f1 | f2\n",
        "                if item not in ck:\n",
        "                    ck.append(item)\n",
        "    return ck"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjY4N746vSVn"
      },
      "source": [
        "def create_freq_item(X, ck, min_support):\n",
        "    \"\"\"\n",
        "    filters the candidate with the specified\n",
        "    minimum support\n",
        "    \"\"\"\n",
        "    # loop through the transaction and compute\n",
        "    # the count for each candidate (item)\n",
        "    item_count = {}\n",
        "    for transaction in X:\n",
        "        for item in ck:\n",
        "            if item.issubset(transaction):\n",
        "                if item not in item_count:\n",
        "                    item_count[item] = 1\n",
        "                else:\n",
        "                    item_count[item] += 1\n",
        "\n",
        "    n_row = X.shape[0]\n",
        "    freq_item = []\n",
        "    item_support = {}\n",
        "\n",
        "    # if the support of an item is greater than the\n",
        "    # min_support, then it is considered as frequent\n",
        "    for item in item_count:\n",
        "        support = item_count[item] / n_row\n",
        "        if support >= min_support:\n",
        "            freq_item.append(item)\n",
        "\n",
        "        item_support[item] = item_count[item]\n",
        "\n",
        "    return freq_item, item_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQEkRY1kvfX5"
      },
      "source": [
        "def apriori(X, min_support):\n",
        "    \"\"\"\n",
        "    pass in the transaction data and the minimum support\n",
        "    threshold to obtain the frequent itemset. Also\n",
        "    store the support for each itemset, they will\n",
        "    be used in the rule generation step\n",
        "    \"\"\"\n",
        "\n",
        "    # the candidate sets for the 1-item is different,\n",
        "    # create them independently from others\n",
        "    c1 = create_candidate_1(X)\n",
        "    freq_item, item_support_dict = create_freq_item(X, c1, min_support)\n",
        "    freq_items = [freq_item]\n",
        "\n",
        "    k = 0\n",
        "    while len(freq_items[k]) > 0:\n",
        "        freq_item = freq_items[k]\n",
        "        ck = create_candidate_k(freq_item, k)\n",
        "        freq_item, item_support = create_freq_item(X, ck, min_support)\n",
        "        if(k==0):\n",
        "            with open('output.txt','w') as f:\n",
        "                for k, v in item_support.items():\n",
        "                    # print(str(list(k)) + str(v))\n",
        "                    if(v>=100):\n",
        "                      f.write(\"itemset: \"+(str(list(k))) + \" count: \"+(str(v))+\"\\n\")\n",
        "\n",
        "            break\n",
        "        freq_items.append(freq_item)\n",
        "        item_support_dict.update(item_support)\n",
        "        k += 1\n",
        "\n",
        "    return freq_items, item_support_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHMS7y4_Hln8",
        "outputId": "c71d83a0-5649-45b3-eb90-87cdfb42576b"
      },
      "source": [
        "trans = []\n",
        "with open('/content/Data/question2/browsing.txt') as f:\n",
        "    contents = f.readlines()\n",
        "    for i in contents:\n",
        "        trans.append(i.split())\n",
        "trans[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['FRO11987', 'ELE17451', 'ELE89019', 'SNA90258', 'GRO99222']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFoSyrsiIfqa"
      },
      "source": [
        "c1 = create_candidate_1(trans)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVIKiZflKx3c",
        "outputId": "d6b0b25d-6161-4057-c23c-dc9a7578ccf9"
      },
      "source": [
        "trans=np.array(trans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2APvTX1NJfnI"
      },
      "source": [
        "freq_item, item_support_dict = create_freq_item(trans, c1, 0.003)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPC_r5tgMIFh"
      },
      "source": [
        "item_support_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx42UfxPKEMp"
      },
      "source": [
        "ck = create_candidate_k(freq_item, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5CLylx0Movl"
      },
      "source": [
        " item_count = {}\n",
        " for transaction in trans:\n",
        "      for item in ck:\n",
        "          if item.issubset(transaction):\n",
        "              if item not in item_count:\n",
        "                  item_count[item] = 1\n",
        "              else:\n",
        "                  item_count[item] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDGMBxHwZJ2s",
        "outputId": "f33f5eb6-514c-4c66-eadd-0015a74a9394"
      },
      "source": [
        "len(item_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlX9LLLTZ9Dg",
        "outputId": "fcf3c514-2e96-4317-c1cb-9a6b8a5ca5b4"
      },
      "source": [
        "conf_list=[]\n",
        "for k, v in item_count.items():\n",
        "      X_and_Y = list(k)\n",
        "      support_X = item_support_dict.get(frozenset({X_and_Y[0]}))\n",
        "      support_Y = item_support_dict.get(frozenset({X_and_Y[1]}))\n",
        "      conf_list.append([X_and_Y,float(v/support_X)])\n",
        "      Y_and_X = X_and_Y[::-1]\n",
        "      conf_list.append([Y_and_X,float(v/support_Y)])\n",
        "conf_list[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['FRO11987', 'ELE17451'], 0.17307692307692307],\n",
              " [['ELE17451', 'FRO11987'], 0.00464516129032258],\n",
              " [['SNA90258', 'FRO11987'], 0.0036363636363636364],\n",
              " [['FRO11987', 'SNA90258'], 0.019230769230769232],\n",
              " [['FRO11987', 'GRO99222'], 0.038461538461538464]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi1fqWJrgowJ",
        "outputId": "ef002448-e62a-4b89-8eb6-5a6c238ae644"
      },
      "source": [
        "sorted_list = sorted(conf_list, key=lambda x: x[1],reverse=True)\n",
        "(sorted_list[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['DAI93865', 'FRO40251'], 1.0],\n",
              " [['GRO85051', 'FRO40251'], 0.999176276771005],\n",
              " [['GRO38636', 'FRO40251'], 0.9906542056074766],\n",
              " [['ELE12951', 'FRO40251'], 0.9905660377358491],\n",
              " [['DAI88079', 'FRO40251'], 0.9867256637168141]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrRszzlQj3Qo"
      },
      "source": [
        "c2 = ck\n",
        "#now we go to part 2:\n",
        "freq_item2, item_support2 = create_freq_item(trans, c2, 0.003)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqiV3CdilDzL"
      },
      "source": [
        "c3 = create_candidate_k(freq_item2, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR_7KUh0ldk8"
      },
      "source": [
        "triple_item_count = {}\n",
        "for transaction in trans:\n",
        "    for item in c3:\n",
        "        if item.issubset(transaction):\n",
        "            if item not in triple_item_count:\n",
        "                triple_item_count[item] = 1\n",
        "            else:\n",
        "                triple_item_count[item] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hupTJOCkl8DF",
        "outputId": "1405cc65-ca30-4686-aece-6ef8e7839c99"
      },
      "source": [
        "triple_conf_list = []\n",
        "for k, v in triple_item_count.items():\n",
        "    X_and_Y_and_Z = list(k)\n",
        "    support_X_Y = item_count.get(frozenset({X_and_Y_and_Z[0],X_and_Y_and_Z[1]}))\n",
        "    support_Y_Z = item_count.get(frozenset({X_and_Y_and_Z[1],X_and_Y_and_Z[2]}))\n",
        "    support_X_Z = item_count.get(frozenset({X_and_Y_and_Z[0],X_and_Y_and_Z[2]}))\n",
        "    triple_conf_list.append([X_and_Y_and_Z, float(v / support_X_Y)])\n",
        "    Z_and_Y_and_X = X_and_Y_and_Z[::-1]\n",
        "    triple_conf_list.append([Z_and_Y_and_X, float(v / support_Y_Z)])\n",
        "    Z_and_Y_and_X[1], Z_and_Y_and_X[2] = Z_and_Y_and_X[2], Z_and_Y_and_X[1]\n",
        "    triple_conf_list.append([Z_and_Y_and_X, float(v / support_X_Z)])\n",
        "sorted_list = sorted(triple_conf_list, key=lambda x: x[1], reverse=True)\n",
        "(sorted_list[:5])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['GRO56989', 'DAI50921', 'DAI62779'], 1.0],\n",
              " [['GRO38636', 'FRO40251', 'ELE17451'], 1.0],\n",
              " [['GRO38636', 'SNA93860', 'FRO40251'], 1.0],\n",
              " [['FRO31317', 'FRO40251', 'GRO38636'], 1.0],\n",
              " [['DAI62779', 'GRO38636', 'FRO40251'], 1.0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVQF1C8cuipp",
        "outputId": "810b49d9-a362-458f-b777-2c5bdab01edc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}